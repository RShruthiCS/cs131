{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f56d50dc-dbf0-4447-a1c6-55e94dffcf00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+\n",
      "|       1| 2019-04-01 00:04:09|  2019-04-01 00:06:35|              1|          0.5|         1|                 N|         239|         239|           1|        4.0|  3.0|    0.5|       1.0|         0.0|                  0.3|         8.8|                 2.5|\n",
      "|       1| 2019-04-01 00:22:45|  2019-04-01 00:25:43|              1|          0.7|         1|                 N|         230|         100|           2|        4.5|  3.0|    0.5|       0.0|         0.0|                  0.3|         8.3|                 2.5|\n",
      "|       1| 2019-04-01 00:39:48|  2019-04-01 01:19:39|              1|         10.9|         1|                 N|          68|         127|           1|       36.0|  3.0|    0.5|      7.95|         0.0|                  0.3|       47.75|                 2.5|\n",
      "|       1| 2019-04-01 00:35:32|  2019-04-01 00:37:11|              1|          0.2|         1|                 N|          68|          68|           2|        3.5|  3.0|    0.5|       0.0|         0.0|                  0.3|         7.3|                 2.5|\n",
      "|       1| 2019-04-01 00:44:05|  2019-04-01 00:57:58|              1|          4.8|         1|                 N|          50|          42|           1|       15.5|  3.0|    0.5|      3.85|         0.0|                  0.3|       23.15|                 2.5|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Start Spark\n",
    "spark = SparkSession.builder.appName(\"TaxiDecisionTree\").getOrCreate()\n",
    "\n",
    "# Load CSV from /tmp\n",
    "df = spark.read.csv(\"/tmp/2019-04.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# Show a few rows\n",
    "df.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5dee16a-48ad-41cd-a713-fb7a626c1093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size: 5946633\n",
      "Testing size: 1486506\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "trainDF, testDF = df.select(\n",
    "    col(\"passenger_count\").cast(\"double\"),\n",
    "    col(\"PULocationID\").alias(\"pickup\").cast(\"double\"),\n",
    "    col(\"DOLocationID\").alias(\"dropoff\").cast(\"double\"),\n",
    "    col(\"total_amount\").cast(\"double\")\n",
    ").randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Show confirmation\n",
    "print(f\"Training size: {trainDF.count()}\")\n",
    "print(f\"Testing size: {testDF.count()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83e4753c-4a0e-420d-af44-9c5c790bd1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import DecisionTreeRegressor\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# Assemble input features into a single vector\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"passenger_count\", \"pickup\", \"dropoff\"],\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n",
    "# Create Decision Tree Regressor\n",
    "dtr = DecisionTreeRegressor(featuresCol=\"features\", labelCol=\"total_amount\")\n",
    "\n",
    "# Create pipeline with assembler + regressor\n",
    "pipeline = Pipeline(stages=[assembler, dtr])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e0e3bc0-2412-4031-aad6-656c620c1aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model = pipeline.fit(trainDF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c64ad65-9bcb-4e9e-a720-780e2633da41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------+-------+------------+------------------+\n",
      "|passenger_count|pickup|dropoff|total_amount|        prediction|\n",
      "+---------------+------+-------+------------+------------------+\n",
      "|            0.0|   1.0|    1.0|       103.3|27.742775399212995|\n",
      "|            0.0|   4.0|    4.0|         6.8|27.742775399212995|\n",
      "|            0.0|   4.0|   33.0|       31.55|15.891463655567376|\n",
      "|            0.0|   4.0|   79.0|         7.8|15.891463655567376|\n",
      "|            0.0|   4.0|  107.0|        11.8|15.891463655567376|\n",
      "|            0.0|   4.0|  144.0|        11.3|17.810129891664225|\n",
      "|            0.0|   4.0|  234.0|        11.0|17.810129891664225|\n",
      "|            0.0|   7.0|  121.0|        28.8|17.810129891664225|\n",
      "|            0.0|   7.0|  223.0|         6.8|17.810129891664225|\n",
      "|            0.0|   7.0|  223.0|         8.3|17.810129891664225|\n",
      "+---------------+------+-------+------------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions\n",
    "predictions = model.transform(testDF)\n",
    "\n",
    "# Show first 10 rows with input features and predicted total_amount\n",
    "predictions.select(\n",
    "    \"passenger_count\", \"pickup\", \"dropoff\", \"total_amount\", \"prediction\"\n",
    ").show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb12fdb0-85c9-429b-b5bc-4558b4eac3d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE): 324.89\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Create evaluator\n",
    "evaluator = RegressionEvaluator(\n",
    "    labelCol=\"total_amount\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"rmse\"\n",
    ")\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49a0718-a322-4674-9072-f54160a92726",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
